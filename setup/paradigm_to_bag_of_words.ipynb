{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert Senate speech data from 114th Congress to bag of words format.\n",
    "\n",
    "The data is provided by [1]. Specifically, we use the `hein-daily` data. To \n",
    "run this script, make sure the relevant files are in \n",
    "`data/senate-speeches-114/raw/`. The files needed for this script are \n",
    "`speeches_114.txt`, `descr_114.txt`, and `114_SpeakerMap.txt`.\n",
    "\n",
    "#### References\n",
    "[1]: Gentzkow, Matthew, Jesse M. Shapiro, and Matt Taddy. Congressional Record \n",
    "     for the 43rd-114th Congresses: Parsed Speeches and Phrase Counts. Palo \n",
    "     Alto, CA: Stanford Libraries [distributor], 2018-01-16. \n",
    "     https://data.stanford.edu/congress_text\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import setup_utils as utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.abspath(\n",
    "    os.path.join(os.path.dirname('.'), os.pardir)) \n",
    "data_dir = os.path.join(project_dir, \"data\\\\paradigms\\\\raw\")\n",
    "save_dir = os.path.join(project_dir, \"data\\\\paradigms\\\\clean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judge Name</th>\n",
       "      <th>Paradigm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Judge ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris Palmer</td>\n",
       "      <td>Tabroom.com is mostly my fault. Therefore I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Hardy</td>\n",
       "      <td>It's been a number of years since I've been an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Paul Wexler</td>\n",
       "      <td>Debate Paradigm Paul Wexler Coach since 1993, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Shunta Jordan</td>\n",
       "      <td>Just a brief update for the high school commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>Bill Smelko</td>\n",
       "      <td>Please email me your speech documents. I have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Judge Name                                           Paradigm\n",
       "Judge ID                                                                  \n",
       "1          Chris Palmer  Tabroom.com is mostly my fault. Therefore I'm ...\n",
       "3           Aaron Hardy  It's been a number of years since I've been an...\n",
       "319         Paul Wexler  Debate Paradigm Paul Wexler Coach since 1993, ...\n",
       "1057      Shunta Jordan  Just a brief update for the high school commun...\n",
       "1088        Bill Smelko  Please email me your speech documents. I have ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_markdown_to_plain_text(markdown_string):\n",
    "\n",
    "    markdown_string = str(markdown_string)\n",
    "    # Remove newlines\n",
    "    plain_text = markdown_string.replace('\\n', ' ')\n",
    "    \n",
    "    # Remove bold formatting (e.g., **text**)\n",
    "    plain_text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', plain_text)\n",
    "    \n",
    "    # Remove backslashes\n",
    "    plain_text = plain_text.replace('\\\\', '')\n",
    "    \n",
    "    # Remove other markdown formatting if needed\n",
    "    plain_text = plain_text.replace('\\t', '')\n",
    "    \n",
    "    return plain_text\n",
    "\n",
    "def fix_spaces(string):\n",
    "    new_string = ' '.join(string.strip().split())\n",
    "    return new_string\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'paradigms.csv'), index_col=0)[['Judge Name', 'Paradigm']]\n",
    "\n",
    "df['Paradigm'] = df['Paradigm'].apply(convert_markdown_to_plain_text)\n",
    "df['Paradigm'] = df['Paradigm'].apply(fix_spaces)\n",
    "df.sort_index(inplace=True)\n",
    "df = df[~df['Judge Name'].isna()]\n",
    "df = df[df['Paradigm'].str.len() > 5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1817,)\n",
      "(1817,)\n",
      "(1817,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "speaker = np.array(df.index.values)\n",
    "\n",
    "speeches = np.array(df['Paradigm'])\n",
    "\n",
    "\n",
    "# Create mapping between names and IDs.\n",
    "speaker_to_speaker_id = dict(\n",
    "    [(y, x) for x, y in enumerate(speaker)])\n",
    "author_indices = np.array(\n",
    "    [speaker_to_speaker_id[s] for s in speaker])\n",
    "author_map = np.array(list(speaker_to_speaker_id.keys()))\n",
    "\n",
    "print(author_map.shape)\n",
    "print(author_indices.shape)\n",
    "print(speaker.shape)\n",
    "len(set(speaker))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'i',\n",
       " 'to',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'you',\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'for',\n",
       " 'it',\n",
       " 'debate',\n",
       " 'if',\n",
       " 'not',\n",
       " 'be',\n",
       " 'are',\n",
       " 'on',\n",
       " 'your',\n",
       " 'have',\n",
       " 'me',\n",
       " 'or',\n",
       " 'as',\n",
       " 'arguments',\n",
       " 'will',\n",
       " 'but',\n",
       " 'my',\n",
       " 's',\n",
       " 'with',\n",
       " 'this',\n",
       " 'do',\n",
       " 'of the',\n",
       " 'should',\n",
       " 'if you',\n",
       " 'don',\n",
       " 'don t',\n",
       " 'what',\n",
       " 'an',\n",
       " 'can',\n",
       " 'think',\n",
       " 'in the',\n",
       " 'more',\n",
       " 'am',\n",
       " 'argument',\n",
       " 'at',\n",
       " 'about',\n",
       " 'i am',\n",
       " 'i will',\n",
       " 'debates',\n",
       " 'so',\n",
       " 'round',\n",
       " 'make',\n",
       " 'm',\n",
       " 'i m',\n",
       " 'they',\n",
       " 'just',\n",
       " 'vote',\n",
       " 'how',\n",
       " 'than',\n",
       " 'other',\n",
       " 'to the',\n",
       " 'the debate',\n",
       " 'why',\n",
       " 'by',\n",
       " 'when',\n",
       " 'to be',\n",
       " 'read',\n",
       " 'i think',\n",
       " 'all',\n",
       " 'team',\n",
       " 'judge',\n",
       " 'most',\n",
       " 'some',\n",
       " 'i have',\n",
       " 'on the',\n",
       " 'there',\n",
       " 'their',\n",
       " 'them',\n",
       " 'also',\n",
       " 'is a',\n",
       " 'from',\n",
       " 'out',\n",
       " 'these',\n",
       " 'you are',\n",
       " 'any',\n",
       " 'please',\n",
       " 'well',\n",
       " 'because',\n",
       " 'that i',\n",
       " 're',\n",
       " 'it is',\n",
       " 'need',\n",
       " 'i don',\n",
       " 'i don t',\n",
       " 'one',\n",
       " 'it s',\n",
       " 'no',\n",
       " 'very',\n",
       " 'important',\n",
       " 'for the']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "stopwords = list(\n",
    "    np.loadtxt('stops.txt',\n",
    "               dtype=str,\n",
    "               delimiter=\",\")[0:100,0])\n",
    "\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=0.001,\n",
    "                                   max_df=0.35, \n",
    "                                   stop_words='english', \n",
    "                                   ngram_range=(1, 3),\n",
    "                                   token_pattern=\"[a-zA-Z]+\")\n",
    "\n",
    "\n",
    "# Learn initial document term matrix. This is only initial because we use it to\n",
    "# identify words to exclude based on author counts.\n",
    "counts = count_vectorizer.fit_transform(speeches)\n",
    "\n",
    "vocabulary = np.array(\n",
    "    [k for (k, v) in sorted(count_vectorizer.vocabulary_.items(), \n",
    "                            key=lambda kv: kv[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'nc place', 'nc order read', 'nc order increase',\n",
       "       'nc offcase', 'nc nr impact', 'nc nr blocks', 'nc need',\n",
       "       'nc read case', 'nc nc', 'nc makes sense', 'nc looked similar',\n",
       "       'nc looked', 'nc likely', 'nc k overview', 'nc interp',\n",
       "       'nc impact', 'nc mention', 'nc framework', 'nc reading',\n",
       "       'nc rebuttals', 'nd seed', 'nd rd', 'ncs nrs', 'ncs framework',\n",
       "       'ncs don t', 'ncs don', 'nc yes', 'nc reads', 'nc topicality',\n",
       "       'nc time', 'nc theory', 'nc starts', 'nc shells', 'nc say',\n",
       "       'nc responds da', 'nc responds', 'nc topic', 'nd speaker',\n",
       "       'nc extended', 'nc doesn t', 'nb s', 'nb cp asked', 'nazis',\n",
       "       'nazi', 'navigable taking tag', 'navigable taking', 'natured',\n",
       "       'nba', 'nature topic', 'nature prefer', 'nature modern',\n",
       "       'nature like', 'nature fiat', 'nature don t', 'nature don',\n",
       "       'nature debates combined', 'nature t', 'nc evidence', 'nc ac secs',\n",
       "       'nc analytical', 'nc doesn', 'nc does', 'nc da', 'nc cps good',\n",
       "       'nc cp s', 'nc cp impact', 'nc counterplans fun', 'nc actually',\n",
       "       'nc counterplans add', 'nc clearly', 'nc blocks', 'nc believe',\n",
       "       'nc beat nr', 'nc beat', 'nc answers', 'nc analytical arguments',\n",
       "       'nc contradictions', 'ndt aware', 'ndt ceda coached',\n",
       "       'ndt ceda debater', 'nearly important',\n",
       "       'nearly familiar literature', 'nearly familiar',\n",
       "       'nearly experience', 'nearly easy', 'nearly case', 'nearly bad',\n",
       "       'nearly impossible resolve', 'nearly argument', 'near plan',\n",
       "       'near perfect', 'near end', 'near dear heart', 'near dear',\n",
       "       'ndt year', 'ndt x', 'nearest person', 'ndt voted northwestern',\n",
       "       'nearly persuasive', 'nebulous vulnerable',\n",
       "       'necessarily justified elaboration', 'necessarily justified',\n",
       "       'necessarily good', 'necessarily defend',\n",
       "       'necessarily debatable opinion', 'necessarily debatable',\n",
       "       'necessarily consider argument', 'nebulous claims',\n",
       "       'necessarily consider', 'necessarily best',\n",
       "       'necessarily believe affirmatives', 'necessarily bad',\n",
       "       'necessarily automatic', 'necessarily argument',\n",
       "       'necessarily affect', 'nebulous vulnerable aff',\n",
       "       'necessarily case', 'ndt ve', 'ndt updates', 'ndt university',\n",
       "       'ndt judged', 'ndt judge', 'ndt generally', 'ndt freshman year',\n",
       "       'ndt freshman', 'ndt elimination round', 'ndt double octo',\n",
       "       'ndt junior senior', 'ndt double', 'ndt coached judged',\n",
       "       'ndt circuit', 'ndt ceda years', 'ndt ceda year',\n",
       "       'ndt ceda worked', 'ndt ceda update', 'ndt ceda healthcare',\n",
       "       'ndt college', 'ndt national', 'ndt notes', 'ndt npda',\n",
       "       'ndt twice broke', 'ndt try', 'ndt times making', 'ndt times ceda',\n",
       "       'ndt team', 'ndt style', 'ndt season', 'ndt s',\n",
       "       'ndt qualifier ndt', 'ndt policy debate', 'ndt policy',\n",
       "       'ndt participant', 'ndt octos', 'ndt octofinalist x',\n",
       "       'ndt octa finalist', 'ndt octa', 'ndt npda npte', 'nature debates',\n",
       "       'nature cp s', 'nature case', 'nature arguments',\n",
       "       'multiple solvency', 'multiple shallow', 'multiple planks kicked',\n",
       "       'multiple pieces evidence', 'multiple pieces', 'multiple perms k',\n",
       "       'multiple paragraphs', 'multiple solvency advocates',\n",
       "       'multiple options', 'multiple k s', 'multiple k',\n",
       "       'multiple judge orientations', 'multiple judge', 'multiple flows',\n",
       "       'multiple flavors', 'multiple events', 'multiple meanings',\n",
       "       'multiple conditional strategies', 'multiple speeches',\n",
       "       'multiple styles', 'music personal narratives', 'music movies',\n",
       "       'music make', 'music audio', 'mushrooms', 'museum', 'muscle',\n",
       "       'multiple strategies', 'murray', 'munday', 'mundane',\n",
       "       'multiple world', 'multiple times debate',\n",
       "       'multiple theory arguments', 'multiple theory',\n",
       "       'multiple styles debate', 'murakami',\n",
       "       'multiple conditional positions', 'multiple competing worlds',\n",
       "       'multiple competing', 'moved dictated', 'moved argument', 'mouths',\n",
       "       'mouth read', 'mountain brook', 'mound',\n",
       "       'motives intentions course', 'moved dictated myopic',\n",
       "       'motives intentions', 'motivate', 'motions', 'moten harney',\n",
       "       'mosley jensen', 'mosley', 'mortal', 'morphs', 'motivating',\n",
       "       'movement institutional', 'movement institutional change',\n",
       "       'movement make', 'multiple case positions', 'multiple case',\n",
       "       'multiple advocacies', 'multiple actors', 'multiplank cps',\n",
       "       'multicultural democracy', 'multiactor fiat',\n",
       "       'multi plank conditional', 'multi actor international', 'muck',\n",
       "       'mt carmel', 'msn com', 'msn', 'moving target implausible',\n",
       "       'moving parts need', 'moving debate', 'movement project',\n",
       "       'music poetry', 'necessarily limited', 'mutated',\n",
       "       'mutually beneficial', 'natal alienation', 'natal',\n",
       "       'nat hs circuit', 'nat hs', 'nat circuit', 'narrowing debate',\n",
       "       'narrow set relevant', 'nate silver', 'narrow set',\n",
       "       'narrativization', 'narratives trump slew', 'narratives trump',\n",
       "       'narratives music', 'narratives elements scholarship',\n",
       "       'narratives elements', 'narrative round win', 'narrow minded',\n",
       "       'narrative performance', 'nation s', 'national circuit ld',\n",
       "       'nature argument', 'nature alt', 'naturally flow',\n",
       "       'naturally defers policymaking', 'naturally defers',\n",
       "       'naturally competitive format', 'naturally competitive',\n",
       "       'national circuit debated', 'nato bad', 'national toc',\n",
       "       'national policy', 'national novice', 'national health insurance',\n",
       "       'national health', 'national circuits years', 'national circuits',\n",
       "       'nationals nd', 'narrative based arguments', 'narrative based',\n",
       "       'narrative argument', 'n experience', 'n double s', 'n double',\n",
       "       'n debate career', 'n debate', 'n cases gonna', 'n cases',\n",
       "       'n flexible', 'n b', 'myopic closed', 'mutually reinforcing',\n",
       "       'mutually inclusive does', 'mutually exclusive plan',\n",
       "       'mutually exclusive net', 'mutually exclusive just',\n",
       "       'mutually exclusive don', 'myopic closed minded', 'n going',\n",
       "       'n heart', 'n isn', 'names don t', 'names don', 'names argument',\n",
       "       'n years college', 'n went', 'n url com', 'n url', 'n time',\n",
       "       'n tend', 'n spend good', 'n reads overview', 'n reads',\n",
       "       'n person', 'n n', 'n majority', 'n knows', 'n isn t',\n",
       "       'mutual respect competitors', 'necessarily make',\n",
       "       'necessarily mean don', 'necessarily mean m', 'need prioritize',\n",
       "       'need pretty', 'need present', 'need prep prep',\n",
       "       'need points order', 'need points', 'need persuaded',\n",
       "       'need prove interpretation', 'need people', 'need offense interp',\n",
       "       'need offense flow', 'need offense defense', 'need offense beat',\n",
       "       'need nr', 'need new', 'need neg', 'need offensive reasons',\n",
       "       'need mutually exclusive', 'need prove particularly',\n",
       "       'need quantify', 'need seconds', 'need remember', 'need rely',\n",
       "       'need related', 'need reduce humanity', 'need reduce',\n",
       "       'need recognize', 'need prove s', 'need reasonably',\n",
       "       'need reason vote', 'need really make', 'need really impact',\n",
       "       'need realize value', 'need realize cherish', 'need read cards',\n",
       "       'need questions', 'need reasonability', 'need mutually',\n",
       "       'need model debate', 'need model', 'need invest time',\n",
       "       'need interact', 'need improve', 'need impacted answer',\n",
       "       'need impact calc', 'need identify', 'need ground',\n",
       "       'need judge direction', 'need good impact', 'need fully',\n",
       "       'need framing', 'need framework understand', 'need frame argument',\n",
       "       'need form', 'need flesh interpretation', 'need flash need',\n",
       "       'need given', 'need justification', 'need justified',\n",
       "       'need justified point', 'need making', 'need lot work',\n",
       "       'need lot explanation', 'need little time', 'need little bit',\n",
       "       'need link k', 'need link impact', 'need line', 'need like',\n",
       "       'need know specific', 'need know round', 'need know minutes',\n",
       "       'need know critique', 'need know argument', 'need know alt',\n",
       "       'need know affirmative', 'need kind', 'need separate',\n",
       "       'need flash', 'need significant improvement', 'need slow speak',\n",
       "       'needed k', 'needed furthermore d', 'needed furthermore',\n",
       "       'needed don t', 'needed don', 'need yell', 'need x',\n",
       "       'needed policy', 'need work make', 'need work disads',\n",
       "       'need win uniqueness', 'need win topical', 'need win substance',\n",
       "       'need win round', 'need win just', 'need win interpretation',\n",
       "       'need work impact', 'need win impacts', 'needed s', 'needed solve',\n",
       "       'needs clear explanation', 'needs claim warrant',\n",
       "       'needs available said', 'needs articulate', 'needs argument',\n",
       "       'needs apply', 'needs aff s', 'needed said', 'needs addressed',\n",
       "       'needham high school', 'needham high', 'needham', 'needed try',\n",
       "       'needed team', 'needed speaker points', 'needed speaker',\n",
       "       'needing extra', 'need win arguments', 'need win alternative',\n",
       "       'need willing', 'need sure', 'need super',\n",
       "       'need substantial improvement', 'need start', 'need spread',\n",
       "       'need spent order', 'need spent', 'need tangible',\n",
       "       'need spend lot', 'need spell', 'need speech',\n",
       "       'need specific discussion', 'need specific case',\n",
       "       'need speak slow', 'need solve aff', 'need slow warrants',\n",
       "       'need spelled', 'need tech', 'need tell evidence', 'need telling',\n",
       "       'need ways apply', 'need watch indicts', 'need warranted',\n",
       "       'need vision debate', 'need vision', 'need viewing computer',\n",
       "       'need view', 'need uniqueness just', 'need unique',\n",
       "       'need understand argument', 'need type', 'need try',\n",
       "       'need thorough', 'need think', 'need things', 'need thing',\n",
       "       'need terminal impact', 'need simply reference', 'morbeck',\n",
       "       'need fight argue', 'need extra explanation', 'necessary win long',\n",
       "       'necessary win framework', 'necessary win debate',\n",
       "       'necessary want', 'necessary vs sufficient', 'necessary vs',\n",
       "       'necessary vote', 'necessary won', 'necessary use',\n",
       "       'necessary topic education', 'necessary speech', 'necessary solve',\n",
       "       'necessary said', 'necessary respond', 'necessary resolve issue',\n",
       "       'necessary require competing', 'necessary understand',\n",
       "       'necessary require', 'necessary won t', 'necessity primarily',\n",
       "       'need affirmative', 'need advocate', 'need advantages',\n",
       "       'need advance', 'need adjust', 'need actually read',\n",
       "       'need actual abuse', 'necessary work', 'need accommodation',\n",
       "       'need abuse', 'need able present', 'need able defend',\n",
       "       'need able articulate', 'need able answer', 'necessity theory',\n",
       "       'necessity sufficiency', 'need access', 'necessary read',\n",
       "       'necessary rarely', 'necessary prove',\n",
       "       'necessarily textually competitive', 'necessarily textually',\n",
       "       'necessarily test', 'necessarily solve case', 'necessarily s',\n",
       "       'necessarily right', 'necessarily reflect', 'necessarily vote',\n",
       "       'necessarily reason', 'necessarily persuasive',\n",
       "       'necessarily opposed', 'necessarily need solvency',\n",
       "       'necessarily method generalizable', 'necessarily method',\n",
       "       'necessarily mean understand', 'necessarily mean persuaded',\n",
       "       'necessarily plan opponents', 'necessarily win',\n",
       "       'necessarily win debate', 'necessary commit',\n",
       "       'necessary means piecing', 'necessary making',\n",
       "       'necessary make decision', 'necessary lose ability',\n",
       "       'necessary lose', 'necessary important', 'necessary going',\n",
       "       'necessary explain', 'necessary especially', 'necessary desirable',\n",
       "       'necessary defense', 'necessary debates', 'necessary d suggest',\n",
       "       'necessary cps', 'necessary context', 'necessary condo',\n",
       "       'necessary comparisons', 'need answer question', 'need fight',\n",
       "       'need answer severance', 'need applied specifically',\n",
       "       'need doing lot', 'need disprove perms', 'need disprove',\n",
       "       'need discussion', 'need disad', 'need different', 'need defense',\n",
       "       'need email chain', 'need defend usfg', 'need debating safety',\n",
       "       'need debating', 'need debates', 'need debater initiate',\n",
       "       'need debater', 'need debate judge', 'need cut speed',\n",
       "       'need defend topical', 'need cut', 'need end', 'need engage case',\n",
       "       'need extend argument', 'need express', 'need explicitly tell',\n",
       "       'need explanation role', 'need explanation neg',\n",
       "       'need explained applied', 'need explain s', 'need engage aff',\n",
       "       'need explain role', 'need explain haven', 'need expand',\n",
       "       'need examples k', 'need evidentiary support', 'need evidentiary',\n",
       "       'need evidence prefer', 'need evaluated', 'need explain method',\n",
       "       'need counter interp', 'need corrected', 'need contextualized',\n",
       "       'need check', 'need catch', 'need case', 'need cards x',\n",
       "       'need card point', 'need camera connection',\n",
       "       'need better application', 'need clarification feel', 'need beat',\n",
       "       'need backed', 'need attention', 'need articulated abuse',\n",
       "       'need articulate terms', 'need arguments', 'need argue',\n",
       "       'need apply', 'need backed defense', 'need clean',\n",
       "       'need clear abuse', 'need clear links',\n",
       "       'need considered isolation', 'need considered', 'need conform',\n",
       "       'need concentrate', 'need compelling', 'need compare impacts',\n",
       "       'need comparative', 'need communicate', 'need commit time',\n",
       "       'need commit', 'need come room', 'need clearly explain',\n",
       "       'need clear statement', 'need clear slow', 'need clear reason',\n",
       "       'need clear plan', 'need clear net', 'need answer tva',\n",
       "       'needs clear impact', 'morally repugnant don', 'morally bad',\n",
       "       'metathesis', 'metatheory', 'metaphysically',\n",
       "       'metaphors depth reasons', 'metaphors depth', 'metaphorically',\n",
       "       'metaphorical literal podium', 'method advocacy',\n",
       "       'metaphorical literal', 'metaphorical interpretation',\n",
       "       'metaphor teams ships', 'metaphor teams', 'metaphor debate',\n",
       "       'meta thoughts', 'meta things', 'meta theory tie',\n",
       "       'metaphorical interpretation topic', 'meta theoretical',\n",
       "       'method assigning', 'method ballot', 'method large',\n",
       "       'method judging', 'method important', 'method impact',\n",
       "       'method generally', 'method generalizable', 'method epistemology',\n",
       "       'method assigning speaker', 'method does resolve',\n",
       "       'method debates think', 'method debate means', 'method debate don',\n",
       "       'method debate doesn', 'method das', 'method comparison',\n",
       "       'method clearly', 'method determining', 'method make',\n",
       "       'meta levels', 'meta issue', 'mess k', 'mess isn t', 'mess isn',\n",
       "       'mess don t', 'mess don', 'merits research', 'merit strategy vs',\n",
       "       'mess k story', 'merit strategy', 'merit justifying',\n",
       "       'merit exception general', 'merit exception',\n",
       "       'mergers acquisitions', 'mergers', 'merger', 'merely test',\n",
       "       'merit justifying critical', 'meta level m', 'message debate',\n",
       "       'messes w ur', 'meta debates', 'meta argument', 'met burden',\n",
       "       'met aff', 'messy theory debate', 'messy round', 'messy poor k',\n",
       "       'message debate community', 'messy poor', 'messy impossible',\n",
       "       'messy hard', 'messy flow extra', 'messy fast try', 'messy debate',\n",
       "       'messing flow', 'messiness', 'messy impossible resolve',\n",
       "       'method performance', 'method point', 'method s',\n",
       "       'michigan michigan', 'michigan gw', 'michigan gonzaga georgetown',\n",
       "       'michigan gonzaga', 'michigan debater', 'michigan debate coach',\n",
       "       'michigan debate', 'michigan michigan state',\n",
       "       'michigan currently year', 'mic quality', 'mic internet',\n",
       "       'miami ohio', 'miami assistant debate', 'miami assistant', 'metro',\n",
       "       'metric just', 'michigan camp', 'metric evaluating debate',\n",
       "       'michigan policy', 'micro aggressions', 'midst',\n",
       "       'middle school policy', 'middle road judge', 'middle pandemic',\n",
       "       'middle option', 'middle eastern', 'middle ar', 'michigan ve',\n",
       "       'mid s good', 'mid high', 'mics don t', 'mics don', 'microscopic',\n",
       "       'micropolitical', 'microphones', 'micro issues', 'mid high s',\n",
       "       'meticulously', 'methods work', 'methods think',\n",
       "       'methodologies application', 'methodologically',\n",
       "       'methodological assumptions', 'methodist university', 'methodist',\n",
       "       'methodical', 'method weighing',\n",
       "       'methodologies application outside', 'method vs method',\n",
       "       'method used', 'method totality ac', 'method totality',\n",
       "       'method thinking', 'method think', 'method tell',\n",
       "       'method solvency', 'method vs', 'methodologies correct',\n",
       "       'methodologies correct rout', 'methodologies essential',\n",
       "       'methods evaluate', 'methods debate does',\n",
       "       'methodology theory performance', 'methodology theory',\n",
       "       'methodology performance ship', 'methodology ontology',\n",
       "       'methodology framework debates', 'methodology framework',\n",
       "       'methodology epistemology ontology', 'methodology don t',\n",
       "       'methodology don', 'methodology debate', 'methodology assumptions',\n",
       "       'methodology aff questions', 'methodology aff',\n",
       "       'methodologies unless', 'methodologies essential kind',\n",
       "       'merely technically', 'merely supporting', 'merely reading',\n",
       "       'merely extending', 'means want critical', 'means vote virtually',\n",
       "       'means vote team', 'means versed', 'means value', 'means usually',\n",
       "       'means usfg', 'means want run', 'means use', 'means unless',\n",
       "       'means understand', 'means unable', 'means turn',\n",
       "       'means try determine', 'means truth', 'means time don',\n",
       "       'means unlikely', 'means thought', 'means way',\n",
       "       'means win argument', 'mechanism framework',\n",
       "       'mechanism explain explain', 'mechanism explain',\n",
       "       'mechanism education', 'mechanism debating', 'mechanism change',\n",
       "       'mechanism better', 'means willing', 'mechanism affirmative',\n",
       "       'measuring', 'measures ensure', 'meant ve', 'meant clear',\n",
       "       'means work', 'means words', 'means win lose', 'meat potatoes',\n",
       "       'means terms topicality', 'means terms education',\n",
       "       'means telling t', 'means safer', 'means rounds', 'means relation',\n",
       "       'means regards', 'means recognize', 'means real world',\n",
       "       'means questions', 'means safer assume', 'means putting',\n",
       "       'means probably higher', 'means probability timeframe',\n",
       "       'means probability', 'means pretty', 'means presumption',\n",
       "       'means preference', 'means practice debate', 'means pull',\n",
       "       'means said', 'means solve', 'means solve aff', 'means tell',\n",
       "       'means technical', 'means teams', 'means team needs',\n",
       "       'means team lose', 'means team conceded', 'means t read',\n",
       "       'means stops', 'means stop writing', 'means stock issues',\n",
       "       'means stock', 'means spend', 'means speech',\n",
       "       'means specific links', 'means solving', 'means solves',\n",
       "       'means solvency', 'mechanism good', 'midterm',\n",
       "       'mechanism good case', 'mechanism plan', 'member debate community',\n",
       "       'member debate', 'meh win', 'meh theory', 'mega',\n",
       "       'meets threshold triggering', 'meets meet', 'member team',\n",
       "       'meets interpretation', 'meetings', 'meet view fair', 'meet view',\n",
       "       'meet threshold prepared', 'meet theory', 'meet standards',\n",
       "       'meet standard topicality', 'meets framework', 'meet opponent s',\n",
       "       'memo', 'memorial high school', 'merely claiming',\n",
       "       'mere existence evidence', 'mere existence', 'mere assertions',\n",
       "       'mentors', 'mentioned view', 'mentioned round', 'memorial high',\n",
       "       'mentioned m', 'mentioned e', 'mentioned ar', 'mention topic',\n",
       "       'mention speech', 'memory things', 'memorized speech', 'memorize',\n",
       "       'mentioned e performance', 'meet opponent', 'meet negs interp',\n",
       "       'meet negs', 'medical magnet hs', 'mediate',\n",
       "       'mechanistically list factors', 'mechanistically list',\n",
       "       'mechanistically', 'mechanistic', 'mechanisms impacts',\n",
       "       'medical school', 'mechanisms good',\n",
       "       'mechanism warrants important', 'mechanism warrants',\n",
       "       'mechanism sympathetic', 'mechanism solve impacts', 'mechanism s',\n",
       "       'mechanism provides default', 'mechanism provides',\n",
       "       'mechanisms evaluating', 'medicare', 'medicine', 'mediocre cards',\n",
       "       'meet need', 'meet minimum threshold', 'meet minimum',\n",
       "       'meet middle', 'meet m', 'meet just', 'meet framework note',\n",
       "       'meet framework', 'meet debate', 'meet counter interpretation',\n",
       "       'meet burden rejoinder', 'meet burden proof',\n",
       "       'meet burden changing', 'meet best', 'meet arguments', 'mediums',\n",
       "       'medium threshold', 'mechanism k', 'midtown west', 'mike davis',\n",
       "       'mild', 'mixed feelings', 'mix things ll', 'mix good',\n",
       "       'mitigators', 'mitigation outright', 'mitigates claim taking',\n",
       "       'mitigates claim', 'ml', 'mitigated case', 'mitigate outweigh',\n",
       "       'mitigate impact', 'mitigate bias try', 'mitigate bias',\n",
       "       'mitigate aff', 'mitchell', 'misused', 'mitigate risk',\n",
       "       'misunderstood', 'mlm', 'mo ndt', 'model debate debates',\n",
       "       'model debate debate', 'model debate arguments',\n",
       "       'model counterplan alternative', 'model counterplan',\n",
       "       'model better policy', 'model activity', 'mma',\n",
       "       'mode versus policymaker'], dtype='<U40')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove phrases spoken by less than 10 Senators.\n",
    "counts_per_author = utils.bincount_2d(author_indices, counts.toarray())\n",
    "min_authors_per_word = 8\n",
    "author_counts_per_word = np.sum(counts_per_author > 0, axis=0)\n",
    "acceptable_words = np.where(\n",
    "    author_counts_per_word >= min_authors_per_word)[0]\n",
    "\n",
    "ranking = author_counts_per_word.argsort()\n",
    "vocabulary[ranking][:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14052"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fit final document-term matrix with modified vocabulary.\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3),\n",
    "                                   vocabulary=vocabulary[acceptable_words])\n",
    "counts = count_vectorizer.fit_transform(speeches)\n",
    "vocabulary = np.array(\n",
    "    [k for (k, v) in sorted(count_vectorizer.vocabulary_.items(), \n",
    "                            key=lambda kv: kv[1])])\n",
    "\n",
    "# Adjust counts by removing unigram/n-gram pairs which co-occur.\n",
    "counts_dense = utils.remove_cooccurring_ngrams(counts, vocabulary)\n",
    "\n",
    "# Remove speeches with not enough words.\n",
    "existing_speeches = np.where(np.sum(counts_dense, axis=1) > 1)[0]\n",
    "counts_dense = counts_dense[existing_speeches]\n",
    "author_indices = author_indices[existing_speeches]\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data.\n",
    "if not os.path.exists(save_dir):\n",
    "  os.makedirs(save_dir)\n",
    "\n",
    "# `counts.npz` is a [num_documents, num_words] sparse matrix containing the\n",
    "# word counts for each document.\n",
    "sparse.save_npz(os.path.join(save_dir, \"counts.npz\"),\n",
    "                sparse.csr_matrix(counts_dense).astype(np.float32))\n",
    "# `author_indices.npy` is a [num_documents] vector where each entry is an\n",
    "# integer indicating the author of the corresponding document.\n",
    "np.save(os.path.join(save_dir, \"author_indices.npy\"), author_indices)\n",
    "# `vocabulary.txt` is a [num_words] vector where each entry is a string\n",
    "# denoting the corresponding word in the vocabulary.\n",
    "np.savetxt(os.path.join(save_dir, \"vocabulary.txt\"), vocabulary, fmt=\"%s\")\n",
    "# `author_map.txt` is a [num_authors] vector of strings providing the name of\n",
    "# each author in the corpus.\n",
    "np.savetxt(os.path.join(save_dir, \"author_map.txt\"), author_map, fmt=\"%s\")\n",
    "# `raw_documents.txt` contains all the documents we ended up using.\n",
    "raw_documents = [document.replace(\"\\n\", ' ').replace(\"\\r\", ' ') \n",
    "                 for document in speeches[existing_speeches]]\n",
    "np.savetxt(os.path.join(save_dir, \"raw_documents.txt\"), \n",
    "           raw_documents, \n",
    "           fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#og dataframe\n",
    "df.to_csv(os.path.join(save_dir, 'id_name_para.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_downloader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
