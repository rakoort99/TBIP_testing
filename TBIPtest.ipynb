{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ec-x1EfUOFY2"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# %pip install numpyro==0.10.1\n",
        "# %pip install optax\n",
        "# %pip install -U jax jaxlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a3c_4DRONw3",
        "outputId": "cd301810-cc34-4ba1-b1f2-f756b70978d7"
      },
      "outputs": [],
      "source": [
        "# ! git clone https://github.com/rakoort99/TBIP_testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZjX1Cv7OV0U",
        "outputId": "cc17aa7a-e8a0-4739-a05e-f9bf8809df13"
      },
      "outputs": [],
      "source": [
        "from jax import random\n",
        "\n",
        "num_topics = 10\n",
        "rng_seed = random.PRNGKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "EjHpfwsN7UiT",
        "outputId": "2e42f130-0d40-4cb0-e3b2-55b0a6ceb40c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_docs: 1806\n",
            "num_authors 1816\n",
            "dim authormap (1816,)\n",
            "dim author indices (1806,)\n"
          ]
        }
      ],
      "source": [
        "from scipy import sparse\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "dataPath = \"data/paradigms/clean/\"\n",
        "\n",
        "# Load data\n",
        "author_indices = jax.device_put(\n",
        "    jnp.load(dataPath + \"author_indices.npy\"), jax.devices(\"gpu\")[0]\n",
        ")\n",
        "\n",
        "counts = sparse.load_npz(dataPath + \"counts.npz\")\n",
        "\n",
        "with open(dataPath + \"vocabulary.txt\", \"r\") as f:\n",
        "    vocabulary = f.readlines()\n",
        "\n",
        "with open(dataPath + \"author_map.txt\", \"r\") as f:\n",
        "    author_map = f.readlines()\n",
        "\n",
        "author_map = np.array(author_map)\n",
        "\n",
        "num_authors = int(author_indices.max() + 1)\n",
        "num_documents, num_words = counts.shape\n",
        "\n",
        "print('num_docs:', num_documents)\n",
        "print('num_authors', num_authors)\n",
        "print('dim authormap', author_map.shape)\n",
        "print('dim author indices', author_indices.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fUYk1s3778xa"
      },
      "outputs": [],
      "source": [
        "pre_initialize_parameters = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mzAVOWQX79JU"
      },
      "outputs": [],
      "source": [
        "# Fit NMF to be used as initialization for TBIP\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "if pre_initialize_parameters:\n",
        "    nmf_model = NMF(\n",
        "        n_components=num_topics, init=\"random\", random_state=0, max_iter=500\n",
        "    )\n",
        "    # Define initialization arrays\n",
        "    initial_document_loc = jnp.log(\n",
        "        jnp.array(np.float32(nmf_model.fit_transform(counts) + 1e-2))\n",
        "    )\n",
        "    initial_objective_topic_loc = jnp.log(\n",
        "        jnp.array(np.float32(nmf_model.components_ + 1e-2))\n",
        "    )\n",
        "else:\n",
        "    rng1, rng2 = random.split(rng_seed, 2)\n",
        "    initial_document_loc = random.normal(rng1, shape=(num_documents, num_topics))\n",
        "    initial_objective_topic_loc = random.normal(rng2, shape=(num_topics, num_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iujK2LZJ9HUV"
      },
      "outputs": [],
      "source": [
        "from numpyro import plate, sample, param\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.distributions import constraints\n",
        "\n",
        "# Define the model and variational family\n",
        "\n",
        "\n",
        "class TBIP:\n",
        "    def __init__(self, N, D, K, V, batch_size, init_mu_theta=None, init_mu_beta=None):\n",
        "        self.N = N  # number of people\n",
        "        self.D = D  # number of documents\n",
        "        self.K = K  # number of topics\n",
        "        self.V = V  # number of words in vocabulary\n",
        "        self.batch_size = batch_size  # number of documents in a batch\n",
        "\n",
        "        if init_mu_theta is None:\n",
        "            init_mu_theta = jnp.zeros([D, K])\n",
        "        else:\n",
        "            self.init_mu_theta = init_mu_theta\n",
        "\n",
        "        if init_mu_beta is None:\n",
        "            init_mu_beta = jnp.zeros([K, V])\n",
        "        else:\n",
        "            self.init_mu_beta = init_mu_beta\n",
        "\n",
        "    def model(self, Y_batch, d_batch, i_batch):\n",
        "        with plate(\"i\", self.N):\n",
        "            # Sample the per-unit latent variables (ideal points)\n",
        "            x = sample(\"x\", dist.Normal())\n",
        "\n",
        "        with plate(\"k\", size=self.K, dim=-2):\n",
        "            with plate(\"k_v\", size=self.V, dim=-1):\n",
        "                beta = sample(\"beta\", dist.Gamma(0.3, 0.3))\n",
        "                eta = sample(\"eta\", dist.Normal())\n",
        "\n",
        "        with plate(\"d\", size=self.D, subsample_size=self.batch_size, dim=-2):\n",
        "            with plate(\"d_k\", size=self.K, dim=-1):\n",
        "                # Sample document-level latent variables (topic intensities)\n",
        "                theta = sample(\"theta\", dist.Gamma(0.3, 0.3))\n",
        "\n",
        "            # Compute Poisson rates for each word\n",
        "            P = jnp.sum(\n",
        "                jnp.expand_dims(theta, 2)\n",
        "                * jnp.expand_dims(beta, 0)\n",
        "                * jnp.exp(\n",
        "                    jnp.expand_dims(x[i_batch], (1, 2)) * jnp.expand_dims(eta, 0)\n",
        "                ),\n",
        "                1,\n",
        "            )\n",
        "\n",
        "            with plate(\"v\", size=self.V, dim=-1):\n",
        "                # Sample observed words\n",
        "                sample(\"Y_batch\", dist.Poisson(P), obs=Y_batch)\n",
        "\n",
        "    def guide(self, Y_batch, d_batch, i_batch):\n",
        "        # This defines variational family. Notice that each of the latent variables\n",
        "        # defined in the sample statements in the model above has a corresponding\n",
        "        # sample statement in the guide. The guide is responsible for providing\n",
        "        # variational parameters for each of these latent variables.\n",
        "\n",
        "        # Also notice it is required that model and the guide have the same call.\n",
        "\n",
        "        mu_x = param(\n",
        "            \"mu_x\", init_value=-1 + 2 * random.uniform(random.PRNGKey(1), (self.N,))\n",
        "        )\n",
        "        sigma_x = param(\n",
        "            \"sigma_y\", init_value=jnp.ones([self.N]), constraint=constraints.positive\n",
        "        )\n",
        "\n",
        "        mu_eta = param(\n",
        "            \"mu_eta\", init_value=random.normal(random.PRNGKey(2), (self.K, self.V))\n",
        "        )\n",
        "        sigma_eta = param(\n",
        "            \"sigma_eta\",\n",
        "            init_value=jnp.ones([self.K, self.V]),\n",
        "            constraint=constraints.positive,\n",
        "        )\n",
        "\n",
        "        mu_theta = param(\"mu_theta\", init_value=self.init_mu_theta)\n",
        "        sigma_theta = param(\n",
        "            \"sigma_theta\",\n",
        "            init_value=jnp.ones([self.D, self.K]),\n",
        "            constraint=constraints.positive,\n",
        "        )\n",
        "\n",
        "        mu_beta = param(\"mu_beta\", init_value=self.init_mu_beta)\n",
        "        sigma_beta = param(\n",
        "            \"sigma_beta\",\n",
        "            init_value=jnp.ones([self.K, self.V]),\n",
        "            constraint=constraints.positive,\n",
        "        )\n",
        "\n",
        "        with plate(\"i\", self.N):\n",
        "            sample(\"x\", dist.Normal(mu_x, sigma_x))\n",
        "\n",
        "        with plate(\"k\", size=self.K, dim=-2):\n",
        "            with plate(\"k_v\", size=self.V, dim=-1):\n",
        "                sample(\"beta\", dist.LogNormal(mu_beta, sigma_beta))\n",
        "                sample(\"eta\", dist.Normal(mu_eta, sigma_eta))\n",
        "\n",
        "        with plate(\"d\", size=self.D, subsample_size=self.batch_size, dim=-2):\n",
        "            with plate(\"d_k\", size=self.K, dim=-1):\n",
        "                sample(\"theta\", dist.LogNormal(mu_theta[d_batch], sigma_theta[d_batch]))\n",
        "\n",
        "    def get_batch(self, rng, Y, author_indices):\n",
        "        # Helper functions to obtain a batch of data, convert from scipy.sparse\n",
        "        # to jax.numpy.array and move to gpu\n",
        "\n",
        "        D_batch = random.choice(rng, jnp.arange(self.D), shape=(self.batch_size,))\n",
        "        Y_batch = jax.device_put(jnp.array(Y[D_batch].toarray()), jax.devices(\"gpu\")[0])\n",
        "        D_batch = jax.device_put(D_batch, jax.devices(\"gpu\")[0])\n",
        "        I_batch = author_indices[D_batch]\n",
        "        return Y_batch, I_batch, D_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cL9x0A709iHr"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "from optax import adam, exponential_decay\n",
        "from numpyro.infer import SVI, TraceMeanField_ELBO\n",
        "from jax import jit\n",
        "\n",
        "num_steps = 50000\n",
        "batch_size = 512  # Large batches are recommended\n",
        "learning_rate = 0.01\n",
        "decay_rate = 0.01\n",
        "\n",
        "tbip = TBIP(\n",
        "    N=num_authors,\n",
        "    D=num_documents,\n",
        "    K=num_topics,\n",
        "    V=num_words,\n",
        "    batch_size=batch_size,\n",
        "    init_mu_theta=initial_document_loc,\n",
        "    init_mu_beta=initial_objective_topic_loc,\n",
        ")\n",
        "\n",
        "svi_batch = SVI(\n",
        "    model=tbip.model,\n",
        "    guide=tbip.guide,\n",
        "    optim=adam(exponential_decay(learning_rate, num_steps, decay_rate)),\n",
        "    loss=TraceMeanField_ELBO(),\n",
        ")\n",
        "\n",
        "# Compile update function for faster training\n",
        "svi_batch_update = jit(svi_batch.update)\n",
        "\n",
        "# Get initial batch. This informs the dimension of arrays and ensures they are\n",
        "# consistent with dimensions (N, D, K, V) defined above.\n",
        "Y_batch, I_batch, D_batch = tbip.get_batch(random.PRNGKey(1), counts, author_indices)\n",
        "\n",
        "# Initialize the parameters using initial batch\n",
        "svi_state = svi_batch.init(\n",
        "    random.PRNGKey(0), Y_batch=Y_batch, d_batch=D_batch, i_batch=I_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zRjKkX2J9_0X"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to create helper function for printing topic\n",
        "\n",
        "def get_topics(\n",
        "    neutral_mean, negative_mean, positive_mean, vocabulary, print_to_terminal=True\n",
        "):\n",
        "    num_topics, num_words = neutral_mean.shape\n",
        "    words_per_topic = 10\n",
        "    top_neutral_words = np.argsort(-neutral_mean, axis=1)\n",
        "    top_negative_words = np.argsort(-negative_mean, axis=1)\n",
        "    top_positive_words = np.argsort(-positive_mean, axis=1)\n",
        "    topic_strings = []\n",
        "    for topic_idx in range(num_topics):\n",
        "        neutral_start_string = \"Neutral  {}:\".format(topic_idx)\n",
        "        neutral_row = [\n",
        "            vocabulary[word] for word in top_neutral_words[topic_idx, :words_per_topic]\n",
        "        ]\n",
        "        neutral_row_string = \", \".join(neutral_row)\n",
        "        neutral_string = \" \".join([neutral_start_string, neutral_row_string])\n",
        "\n",
        "        positive_start_string = \"Positive {}:\".format(topic_idx)\n",
        "        positive_row = [\n",
        "            vocabulary[word] for word in top_positive_words[topic_idx, :words_per_topic]\n",
        "        ]\n",
        "        positive_row_string = \", \".join(positive_row)\n",
        "        positive_string = \" \".join([positive_start_string, positive_row_string])\n",
        "\n",
        "        negative_start_string = \"Negative {}:\".format(topic_idx)\n",
        "        negative_row = [\n",
        "            vocabulary[word] for word in top_negative_words[topic_idx, :words_per_topic]\n",
        "        ]\n",
        "        negative_row_string = \", \".join(negative_row)\n",
        "        negative_string = \" \".join([negative_start_string, negative_row_string])\n",
        "\n",
        "        if print_to_terminal:\n",
        "            topic_strings.append(negative_string)\n",
        "            topic_strings.append(neutral_string)\n",
        "            topic_strings.append(positive_string)\n",
        "            topic_strings.append(\"==========\")\n",
        "        else:\n",
        "            topic_strings.append(\n",
        "                \"  \\n\".join([negative_string, neutral_string, positive_string])\n",
        "            )\n",
        "\n",
        "    if print_to_terminal:\n",
        "        all_topics = \"{}\\n\".format(np.array(topic_strings))\n",
        "    else:\n",
        "        all_topics = np.array(topic_strings)\n",
        "    return all_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "17ZjXgRs-E5D",
        "outputId": "80c511c2-8322-41b1-b1ea-151cac5f3580"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Init loss: 415479.9688; Avg loss (last 100 iter):  1148.5387:   5%|▍         | 2495/50000 [00:27<07:40, 103.09it/s] /home/rakoort/miniconda3/envs/numpyro_real/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:3652: UserWarning: 'kind' argument to argsort is ignored; only 'stable' sorts are supported.\n",
            "  warnings.warn(\"'kind' argument to argsort is ignored; only 'stable' sorts \"\n",
            "Init loss: 415479.9688; Avg loss (last 100 iter):   809.9194: 100%|██████████| 50000/50000 [08:15<00:00, 100.90it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run SVI\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "print_steps = 100\n",
        "print_intermediate_results = False\n",
        "\n",
        "rngs = random.split(random.PRNGKey(2), num_steps)\n",
        "losses = []\n",
        "pbar = tqdm(range(num_steps))\n",
        "\n",
        "\n",
        "for step in pbar:\n",
        "    Y_batch, I_batch, D_batch = tbip.get_batch(rngs[step], counts, author_indices)\n",
        "    svi_state, loss = svi_batch_update(\n",
        "        svi_state, Y_batch=Y_batch, d_batch=D_batch, i_batch=I_batch\n",
        "    )\n",
        "\n",
        "    loss = loss / counts.shape[0]\n",
        "    losses.append(loss)\n",
        "    if step % print_steps == 0 or step == num_steps - 1:\n",
        "        pbar.set_description(\n",
        "            \"Init loss: \"\n",
        "            + \"{:10.4f}\".format(jnp.array(losses[0]))\n",
        "            + f\"; Avg loss (last {print_steps} iter): \"\n",
        "            + \"{:10.4f}\".format(jnp.array(losses[-100:]).mean())\n",
        "        )\n",
        "\n",
        "    if (step + 1) % 2500 == 0 or step == num_steps - 1:\n",
        "        # Save intermediate results\n",
        "        estimated_params = svi_batch.get_params(svi_state)\n",
        "\n",
        "        neutral_mean = (\n",
        "            estimated_params[\"mu_beta\"] + estimated_params[\"sigma_beta\"] ** 2 / 2\n",
        "        )\n",
        "\n",
        "        positive_mean = (\n",
        "            estimated_params[\"mu_beta\"]\n",
        "            + estimated_params[\"mu_eta\"]\n",
        "            + (estimated_params[\"sigma_beta\"] ** 2 + estimated_params[\"sigma_eta\"] ** 2)\n",
        "            / 2\n",
        "        )\n",
        "\n",
        "        negative_mean = (\n",
        "            estimated_params[\"mu_beta\"]\n",
        "            - estimated_params[\"mu_eta\"]\n",
        "            + (estimated_params[\"sigma_beta\"] ** 2 + estimated_params[\"sigma_eta\"] ** 2)\n",
        "            / 2\n",
        "        )\n",
        "\n",
        "        np.save(\"neutral_topic_mean.npy\", neutral_mean)\n",
        "        np.save(\"negative_topic_mean.npy\", positive_mean)\n",
        "        np.save(\"positive_topic_mean.npy\", negative_mean)\n",
        "\n",
        "        topics = get_topics(neutral_mean, positive_mean, negative_mean, vocabulary)\n",
        "\n",
        "        with open(\"topics.txt\", \"w\") as f:\n",
        "            print(topics, file=f)\n",
        "\n",
        "        authors = pd.DataFrame(\n",
        "            {\"name\": author_map, \"ideal_point\": np.array(estimated_params[\"mu_x\"])}\n",
        "        )\n",
        "        authors.to_csv(\"authors.csv\")\n",
        "\n",
        "        if print_intermediate_results:\n",
        "            print(f\"Results after {step} steps.\")\n",
        "            print(topics)\n",
        "            sorted_authors = \"Authors sorted by their ideal points: \" + \",\".join(\n",
        "                list(authors.sort_values(\"ideal_point\")[\"name\"])\n",
        "            )\n",
        "            print(sorted_authors.replace(\"\\n\", \" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "MLGR-FFvXhyf",
        "outputId": "1e701a1b-8433-4ec7-ce37-99444abe3552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Negative 0: decision\\n, clash\\n, speeches\\n, decisions\\n, students\\n, usually\\n, persuasive\\n, role\\n, activity\\n, examples\\n'\n",
            " 'Neutral  0: activity\\n, decision\\n, line\\n, community\\n, clash\\n, issues\\n, particular\\n, each\\n, role\\n, claims\\n'\n",
            " 'Positive 0: paperless\\n, line\\n, community\\n, while\\n, activity\\n, particular\\n, resolution\\n, result\\n, overviews\\n, strategy\\n'\n",
            " '=========='\n",
            " 'Negative 1: ld\\n, pf\\n, disclosure\\n, fw\\n, wiki\\n, phil\\n, speaks\\n, opponent\\n, traditional\\n, tricks\\n'\n",
            " 'Neutral  1: high school\\n, ld\\n, stuff\\n, care\\n, coach\\n, year\\n, email chain\\n, judged\\n, coached\\n, now\\n'\n",
            " 'Positive 1: high school\\n, judged\\n, coached\\n, year\\n, now\\n, hs\\n, ndt\\n, haven\\n, went\\n, coach\\n'\n",
            " '=========='\n",
            " 'Negative 2: fairness\\n, model\\n, likely\\n, presumption\\n, absent\\n, threshold\\n, whether\\n, reasonability\\n, kick\\n, judges\\n'\n",
            " 'Neutral  2: fairness\\n, seems\\n, model\\n, fiat\\n, kick\\n, risk\\n, likely\\n, less\\n, could\\n, conditionality\\n'\n",
            " 'Positive 2: thought\\n, counterplans\\n, legal\\n, persuasive\\n, counterplan\\n, seems\\n, may\\n, political\\n, defend\\n, question\\n'\n",
            " '=========='\n",
            " 'Negative 3: speed\\n, parli\\n, nfa ld\\n, rules\\n, fine\\n, default\\n, rounds\\n, weighing\\n, run\\n, slow down\\n'\n",
            " 'Neutral  3: run\\n, speed\\n, performance\\n, open\\n, fun\\n, fine\\n, running\\n, rules\\n, end\\n, clearly\\n'\n",
            " 'Positive 3: fun\\n, performance\\n, run\\n, enjoy\\n, open\\n, expect\\n, respectful\\n, ran\\n, alternative\\n, running\\n'\n",
            " '=========='\n",
            " 'Negative 4: perm\\n, advocacy\\n, offense\\n, alternative\\n, claims\\n, competition\\n, different\\n, either\\n, question\\n, defend\\n'\n",
            " 'Neutral  4: counterplans\\n, alternative\\n, interpretation\\n, counterplan\\n, conditionality\\n, kritiks\\n, resolution\\n, reason\\n, affirmatives\\n, reject\\n'\n",
            " 'Positive 4: conditionality\\n, kritiks\\n, counterplans\\n, disads\\n, politics\\n, cps\\n, tend\\n, literature\\n, listen\\n, persuasive\\n'\n",
            " '=========='\n",
            " 'Negative 5: problem\\n, claim\\n, ought\\n, had\\n, either\\n, burden\\n, answer\\n, made\\n, substantive\\n, anything\\n'\n",
            " 'Neutral  5: claim\\n, approach\\n, claims\\n, may\\n, anything\\n, example\\n, philosophy\\n, such\\n, relevant\\n, non\\n'\n",
            " 'Positive 5: philosophy\\n, social\\n, experience\\n, certain\\n, our\\n, may\\n, professor\\n, again\\n, relevant\\n, department\\n'\n",
            " '=========='\n",
            " 'Negative 6: resolution\\n, pf\\n, opponent\\n, paradigm\\n, rebuttal\\n, summary\\n, may\\n, section\\n, standard\\n, rounds\\n'\n",
            " 'Neutral  6: opponent\\n, opponents\\n, ideas\\n, may\\n, own\\n, such\\n, resolution\\n, cases\\n, value\\n, speeches\\n'\n",
            " 'Positive 6: winning\\n, opponents\\n, weigh\\n, towards\\n, research\\n, activity\\n, usma\\n, presented\\n, ideas\\n, military\\n'\n",
            " '=========='\n",
            " 'Negative 7: clipping\\n, marked\\n, line\\n, email chain\\n, along\\n, doc\\n, card\\n, stop\\n, online\\n, asking\\n'\n",
            " 'Neutral  7: card\\n, answer\\n, cx\\n, line\\n, speeches\\n, after\\n, prep time\\n, tend\\n, issue\\n, stop\\n'\n",
            " 'Positive 7: paperless\\n, prep time\\n, might\\n, file\\n, computer\\n, jumping\\n, flash drive\\n, may\\n, answer\\n, shouldn\\n'\n",
            " '=========='\n",
            " 'Negative 8: he\\n, our\\n, his\\n, words\\n, talk\\n, us\\n, mind\\n, were\\n, must\\n, its\\n'\n",
            " 'Neutral  8: our\\n, world\\n, its\\n, game\\n, us\\n, life\\n, had\\n, now\\n, he\\n, words\\n'\n",
            " 'Positive 8: game\\n, politics\\n, love\\n, stories\\n, story\\n, education\\n, action\\n, back\\n, world\\n, interested\\n'\n",
            " '=========='\n",
            " 'Negative 9: framing\\n, line\\n, model\\n, speaks\\n, interp\\n, clash\\n, offense\\n, cx\\n, condo\\n, thing\\n'\n",
            " 'Neutral  9: alt\\n, fw\\n, perm\\n, args\\n, ks\\n, whatever\\n, arg\\n, fine\\n, condo\\n, cps\\n'\n",
            " 'Positive 9: cps\\n, ks\\n, perm\\n, alt\\n, das\\n, whatever\\n, smart\\n, args\\n, being said\\n, net benefit\\n'\n",
            " '==========']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(topics)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
